{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "name": "XLNet.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agemagician/ProtTrans/blob/master/Embedding/PyTorch/Basic/ProtXLNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjIDWEXCJ0b6"
      },
      "source": [
        "<h3> Extracting protein sequences' features using ProtXLNet pretrained-model <h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD2-XqmqJ0b7"
      },
      "source": [
        "<b>1. Load necessry libraries including huggingface transformers<b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3bTean9J-7k"
      },
      "source": [
        "!pip install -q transformers"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIy-Dk-OJ0b8"
      },
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel, pipeline\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import requests\n",
        "from tqdm.auto import tqdm"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7Op-POnJ0cI"
      },
      "source": [
        "<b>2. Load the vocabulary and ProtXLNet Model<b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiWe3_MEJ0cJ",
        "outputId": "e223087a-e526-4a09-b29e-877c81d56cc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"Rostlab/prot_xlnet\", do_lower_case=False)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/configuration_xlnet.py:212: FutureWarning: This config doesn't use attention memories, a core feature of XLNet. Consider setting `men_len` to a non-zero value, for example `xlnet = XLNetLMHeadModel.from_pretrained('xlnet-base-cased'', mem_len=1024)`, for accurate training performance as well as an order of magnitude faster inference. Starting from version 3.5.0, the default parameter will be 1024, following the implementation in https://arxiv.org/abs/1906.08237\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIAg52ixJ0cN",
        "outputId": "2841c6d0-ca29-4992-a320-c96be6d8e9d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "model = AutoModel.from_pretrained(\"Rostlab/prot_xlnet\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/configuration_xlnet.py:212: FutureWarning: This config doesn't use attention memories, a core feature of XLNet. Consider setting `men_len` to a non-zero value, for example `xlnet = XLNetLMHeadModel.from_pretrained('xlnet-base-cased'', mem_len=1024)`, for accurate training performance as well as an order of magnitude faster inference. Starting from version 3.5.0, the default parameter will be 1024, following the implementation in https://arxiv.org/abs/1906.08237\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jkCctT1J0cS"
      },
      "source": [
        "<b>3. Load the model into the GPU if avilabile<b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cifZjuMbJ0cS"
      },
      "source": [
        "fe = pipeline('feature-extraction', model=model, tokenizer=tokenizer,device=0)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCAdlY5YJ0cW"
      },
      "source": [
        "<b>4. Create or load sequences and map rarely occured amino acids (U,Z,O,B) to (unk)<b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nYqFMDRJ0cX"
      },
      "source": [
        "sequences_Example = [\"A E T C Z A O\",\"S K T Z P\"]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fSzAeM9J0cc"
      },
      "source": [
        "sequences_Example = [re.sub(r\"[UZOB]\", \"<unk>\", sequence) for sequence in sequences_Example]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zc2cEpE7J0cg"
      },
      "source": [
        "<b>5. Extracting sequences' features and covert the output to numpy if needed<b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNowPJYgJ0ch",
        "outputId": "95c2aa9f-29b2-407a-9aea-b1ba6215d647",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "embedding = fe(sequences_Example)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/modeling_xlnet.py:298: UserWarning: Mixed memory format inputs detected while calling the operator. The operator will output contiguous tensor even if some of the inputs are in channels_last format. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorIterator.cpp:918.)\n",
            "  attn_score = (ac + bd + ef) * self.scale\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7QLt3qWJ0cl"
      },
      "source": [
        "embedding = np.array(embedding)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uocPT992J0cy",
        "outputId": "680f0076-fc83-4b89-a489-658120224d35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "print(embedding)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[ 5.69581151e-01 -8.12228918e-01  1.51267755e+00 ... -3.47373217e-01\n",
            "   -1.97737479e+00  1.02282667e+00]\n",
            "  [ 2.76618432e-02 -6.71196342e-01  9.98872995e-01 ...  7.27679431e-02\n",
            "   -1.62625897e+00 -8.44636653e-03]\n",
            "  [ 2.20985517e-01 -5.26815653e-01  6.64870739e-01 ...  4.78135161e-02\n",
            "   -1.39787018e+00  3.08237225e-01]\n",
            "  ...\n",
            "  [-3.64925861e-01 -8.19322586e-01  4.81532544e-01 ...  2.35715851e-01\n",
            "   -6.73881412e-01 -1.06030190e+00]\n",
            "  [ 4.51357126e-01 -8.96942556e-01  4.00962412e-01 ... -1.93733007e-01\n",
            "   -5.60827494e-01 -2.78550863e-01]\n",
            "  [ 3.18279147e-01 -1.61192894e+00  4.94404495e-01 ... -2.51359016e-01\n",
            "   -1.32738993e-01 -1.23080434e-02]]\n",
            "\n",
            " [[ 1.91231221e-01  1.84447747e-02 -1.82828668e-03 ... -4.36504602e-01\n",
            "    2.18437910e-02 -1.59096792e-01]\n",
            "  [ 2.63838947e-01 -6.02974333e-02 -1.12759480e-02 ... -2.28307560e-01\n",
            "   -3.21159273e-01  1.10597484e-01]\n",
            "  [ 8.65127444e-01 -1.61870778e-01 -1.75775602e-01 ...  3.56552184e-01\n",
            "   -2.34119326e-01  4.93937097e-02]\n",
            "  ...\n",
            "  [ 4.84942824e-01  6.79003239e-01  3.08672160e-01 ...  7.47227594e-02\n",
            "   -3.86941940e-01 -3.16800058e-01]\n",
            "  [ 8.82356286e-01  1.08732736e+00  1.10505998e-01 ...  2.86997825e-01\n",
            "   -1.13194597e+00  7.79414624e-02]\n",
            "  [ 5.38627028e-01 -1.53360534e-02 -6.67607486e-01 ...  6.61961377e-01\n",
            "    1.94283780e-02 -7.00097680e-01]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wGuhtK3J0c1"
      },
      "source": [
        "<b>Optional: Remove padding ([PAD]) and special tokens ([CLS],[SEP]) that is added by ProtXLNet model<b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZSpwbj5J0c1"
      },
      "source": [
        "features = [] \n",
        "for seq_num in range(len(embedding)):\n",
        "    seq_len = len(sequences_Example[seq_num].replace(\" \", \"\"))\n",
        "    padded_seq_len = len(embedding[seq_num])\n",
        "    start_Idx = padded_seq_len-seq_len-2\n",
        "    end_Idx = padded_seq_len-2\n",
        "    seq_emd = embedding[seq_num][start_Idx:end_Idx]\n",
        "    features.append(seq_emd)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTJ1lTjQJ0c6",
        "outputId": "76a3857d-1732-45c4-d231-f5f08def2224",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "print(features)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([[ 0.02766184, -0.67119634,  0.998873  , ...,  0.07276794,\n",
            "        -1.62625897, -0.00844637],\n",
            "       [ 0.22098552, -0.52681565,  0.66487074, ...,  0.04781352,\n",
            "        -1.39787018,  0.30823722],\n",
            "       [ 0.98757672, -1.03212094,  0.99680483, ..., -0.33855975,\n",
            "        -1.51521766,  1.05237162],\n",
            "       [ 0.70799863, -0.66436082,  0.85833853, ..., -0.02473419,\n",
            "        -1.51670933, -0.21759486],\n",
            "       [-0.14213729, -0.86483812,  0.81442761, ..., -0.32999155,\n",
            "        -0.23385341, -1.71955049],\n",
            "       [-0.36492586, -0.81932259,  0.48153254, ...,  0.23571585,\n",
            "        -0.67388141, -1.0603019 ]]), array([], shape=(0, 1024), dtype=float64)]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}